<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title></title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="./css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="./css/theme/skydark.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? './css/print/pdf.css' : './css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="./lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">


<section><section id="section" class="titleslide slide level1" data-background="./img/title.jpg"><h1></h1></section><section id="section-1" class="slide level2" data-background="./img/screen-wonderland.png">
<h1></h1>
<aside class="notes">
<ul>
<li>Digital wonderland at fingers' reach</li>
</ul>
</aside>
</section><section id="section-2" class="slide level2" data-background="./img/screen-prisoners.png">
<h1></h1>
<aside class="notes">
<ul>
<li>But cannot touch it</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="a-humane-representation-of-thought">A <strong>Humane</strong> Representation of Thought</h3>
<img src="./img/ascent-of-man.jpg" height="300px">
<aside class="notes">
<ul>
<li>Technology constrain our bodies</li>
<li>Only eye and fingers working</li>
<li>Bodies have been neglected</li>
<li>Tip of finger interaction is limiting. Not humane.</li>
<li>Evolution made it so that we think <em>with all our senses</em></li>
</ul>
</aside>
<!-- Attention -->
</section><section id="section-3" class="slide level2" data-background="./img/sur-fake-5-crop.jpg">
<h1></h1>
<aside class="notes">
<ul>
<li>Devices became portable</li>
<li>But require our whole attention</li>
<li>Either IN the screen our OUT in the world</li>
</ul>
</aside>
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
<div class="copyright" style="right:0px;color:rgb(255,255,255);">
Source: Antoine Geiger's SUR-FAKE
</div>
</section><section class="slide level2">

<h3 id="real-world">Real World</h3>
<p>We <strong>know</strong> how it works</p>
</section><section id="section-4" class="slide level2" data-transition="fade">
<h1></h1>
<p><img src="./img/intro-mug.png" height="600px" style="box-shadow: none; background: none;"></p>
</section><section id="section-5" class="slide level2" data-transition="fade">
<h1></h1>
<p><img src="./img/intro-mug-affordance.png" height="600px" style="box-shadow: none; background: none;"></p>
</section><section id="augmented-objects" class="slide level2">
<h1>Augmented Objects</h1>
<img src="./img/intro-mug.jpg" height="400px"> <img src="./img/intro-mug-augmented.jpg" height="400px">
<aside class="notes">
<ul>
<li>For example, we can augment a normal mug with different functions:
<ul>
<li>Displaying remaining steeping time</li>
<li>Displaying temperature of liquid inside</li>
<li>Handle turns green when everything is OK</li>
</ul></li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="interaction">Interaction</h3>
<p>How can we <em>interact</em> with digital content hosted on physical objects?</p>
<!-- Contribution on interaction -->
</section><section id="section-6" class="slide level2" data-background="./img/cursar-teaser.png">
<h1></h1>
<aside class="notes">
<p>The evaluation of the use of 2D pointing devices – mouse and graphics tablet – in a pointing task in a SAR context compared to a screen condition.</p>
</aside>
</section><section id="section-7" class="slide level2" data-background="./img/tports-video-teaser.png">
<h1></h1>
<aside class="notes">
<p>The design, implementation and evaluation of a system enabling the interaction between a typical desktop computer environ- ment – traditional screens, mouse and keyboard – with tangible augmented objects, considering an object design scenario as a main thread.</p>
</aside>
</section><section class="slide level2">

<h3 id="introspection">Introspection</h3>
<p>How can we use augmented objects to reveal hidden information about <em>our own selves</em>?</p>
</section><section id="section-8" class="slide level2" data-background="./img/teegi-teaser.jpg">
<h1></h1>
</section><section id="section-9" class="slide level2" data-background="./img/tobe-coherence.jpg">
<h1></h1>
<!-- Related work -->
</section></section>
<section><section id="context" class="titleslide slide level1"><h1>Context</h1></section><section class="slide level2">

<h3 id="related-areas">Related Areas</h3>
<ul>
<li class="fragment">Ubiquitous Computing &amp; Calm Technologies</li>
<li class="fragment">Physiological &amp; Affective Computing</li>
<li class="fragment">Tangible User Interfaces</li>
<li class="fragment">Augmented Reality</li>
</ul>
</section><section class="slide level2">

<h3 id="ubicomp-calm-technologies">Ubicomp &amp; Calm Technologies</h3>
</section><section class="slide level2">

<h3 id="physiological-affective-computing">Physiological &amp; Affective Computing</h3>
</section><section class="slide level2">

<h3 id="tangible-user-interfaces">Tangible User Interfaces</h3>
<p><img src="./img/radical-atoms.png" height="500px"></p>
</section><section class="slide level2">

<h3 id="organic-user-interfaces">Organic User Interfaces</h3>
<p><img src="./img/dynacan-oui.jpg" height="500px"></p>
</section><section class="slide level2">

<h3 id="augmented-reality">Augmented Reality</h3>
</section><section class="slide level2">

<h3 id="video-see-through">Video see-through</h3>
<img src="./img/intro-ar-video-see-through.png">
<aside class="notes">
<ul>
<li>Traditional way is to use video see-through</li>
<li>Can also uses head mounted display</li>
<li>However: requires hardware for user</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="spatial-augmented-reality"><em>Spatial</em> Augmented Reality</h3>
<p>Uses projectors or screens <em>in the environments</em> to display information spatially related to this environment</p>
<aside class="notes">
<ul>
<li>SAR instead uses projector or screens <em>in the environment</em></li>
<li>Link with Ubicomp</li>
</ul>
</aside>
<!-- SAR -->
</section><section id="section-10" class="slide level2" data-transition="fade">
<h1></h1>
<p><img src="./img/intro-mug-sar.png"></p>
<aside class="notes">
<ul>
<li>Example mug from before</li>
<li>Normal mug + projector...</li>
</ul>
</aside>
</section><section id="section-11" class="slide level2" data-transition="fade">
<h1></h1>
<p><img src="./img/intro-mug-sar-augmented.png"></p>
<aside class="notes">
<ul>
<li>Creates augmented mug</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="projection-mapping">Projection Mapping</h3>
<p><img src="./img/VividSydney-OperaHouseSails.jpg" width="700px"> <!-- Taken from https://en.wikipedia.org/wiki/Projection_mapping#/media/File:Vivid_Sydney_-_Opera_House_sails_(9002375891).jpg --></p>
<p><small>Source: The Sydney Opera House during the 2013 Vivid Sydney projection display</small></p>
<aside class="notes">
<ul>
<li>SAR is most known as a medium used to create impressive multimedia events</li>
<li>e.g. when projecting on buildings</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="augmented-objects-1">Augmented Objects</h3>
<p><img src="./img/sar-clock.jpg" height="400px"> <img src="./img/teegi-inverse-model.jpg" height="400px"></p>
<aside class="notes">
<ul>
<li>It can also be used to create augmented objects</li>
<li>In these two pictures, <em>white</em> physical objects</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="how-does-it-work">How does it work?</h3>
<!-- TODO: Declutter images -->
</section><section id="section-12" class="slide level2" data-background="./img/sar-pipeline.png">
<h1></h1>
<!-- TODO: Declutter images -->
</section><section id="section-13" class="slide level2" data-background="./img/sar-pipeline-virtual.png">
<h1></h1>
</section><section class="slide level2">

<h3 id="what-is-it-good-for">What is it good for?</h3>
</section><section class="slide level2">

<h3 id="pros">Pros</h3>
<ul>
<li class="fragment">Anchored in the <em>real world</em></li>
<li class="fragment">User is free</li>
<li class="fragment">Scales well</li>
<li class="fragment">Collaboration</li>
</ul>
</section><section class="slide level2">

<h3 id="cons">Cons</h3>
<ul>
<li class="fragment">Projection surface</li>
<li class="fragment">Shadows</li>
<li class="fragment">Complexity</li>
<li class="fragment"><em>Interaction</em>
<aside class="notes">
<p>Complexity: Calibration with multiple devices (esp. /w multi-proj setup)</p>
</aside></li>
</ul>
</section></section>
<section><section id="interaction-1" class="titleslide slide level1"><h1>Interaction</h1></section><section id="section-14" class="slide level2" data-background="./img/cursar-teaser.png">
<h1></h1>
<aside class="notes">
<ul>
<li>We focus on the creation of <em>hybrid environments</em></li>
<li>Desktop computers are still good platforms for content creation</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="indirect-pointing-methods">Indirect pointing methods</h3>
<p>Using standard 2D pointing devices such as a <em>mouse</em> or a <em>graphics tablet</em></p>
</section><section class="slide level2">

<h3 id="indirect-pointing-methods-1">Indirect pointing methods</h3>
<ul>
<li class="fragment">Good for prolonged work</li>
<li class="fragment">Precise</li>
<li class="fragment">Allow for <em>hybrid</em> applications</li>
<li class="fragment">Works with objects that are:
<ul>
<li class="fragment">Complex</li>
<li class="fragment">Fragile</li>
<li class="fragment">Distant</li>
</ul></li>
</ul>
<!--
---

### Direct Touch
- "Natural"
- Anchored in reality

---

### But...
- What if object is...
    + Complex
    + Fragile
    + Distant
- Fat finger problem
- Tiring for long stretches of time

<div class="notes">
- Complex: with complex topology where you cannot touch everywhere (e.g. concave)
- Fragile: e.g. museum
</div>
-->
</section></section>
<section><section id="pointing-in-sar" class="titleslide slide level1"><h1>Pointing in SAR</h1></section><section id="section-15" class="slide level2" data-transition="fade">
<h1></h1>
<h3 id="standard-way-of-pointing">Standard way of pointing</h3>
<img src="./img/cursar-virtual-pointing.png" height="500px">
<p class="fragment">
Now what happens if...
</p>
</section><section id="section-16" class="slide level2" data-transition="fade">
<h1></h1>
<h3 id="removing-the-screen">Removing the screen</h3>
<img src="./img/cursar-virtual-pointing-no-screen.png" height="500px">
<p class="fragment">
Does pointing still works without a screen?
</p>
</section><section id="study" class="slide level2">
<h1>Study</h1>
</section><section class="slide level2">

<h3 id="questions">Questions</h3>
<p>Differences between <em>SCREEN</em> and <em>SAR</em> conditions for pointing?</p>
<p>Does pointing in SAR follows Fitts' law?</p>
</section><section id="section-17" class="slide level2" data-transition="fade">
<h1></h1>
<h3 id="pointing-technique">Pointing technique</h3>
<p><img src="./img/cursar-virtual-pointing.png" height="500px"></p>
</section><section id="section-18" class="slide level2" data-transition="fade">
<h1></h1>
<h3 id="pointing-technique-1">Pointing technique</h3>
<p><img src="./img/cursar-virtual-pointing-window.png" height="500px"></p>
</section><section class="slide level2">

<h3 id="apparatus">Apparatus</h3>
<p><img src="./img/cursar-setup.png" width="950px" style="background:none; border:none; box-shadow:none;"></p>
<aside class="notes">
<ul>
<li>A: Circle-shaped cursor that follows the geometry of the real world</li>
<li>B: Plane onto which cursor is mapped
<ul>
<li>In SAR, plane is virtual</li>
<li>In SCREEN condition, we use a wooden panel to create a screen there</li>
</ul></li>
<li>C: Guide displayed on the table to help know where the cursor is located</li>
<li>D: Position of the user is known</li>
<li>E: Projector
<ul>
<li>Augment real cube in SAR condition</li>
<li>Projects a virtual cube in SCREEN condition</li>
</ul></li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="screen-vs-sar">SCREEN vs SAR</h3>
<p><img src="./img/cursar-screen.jpg" width="450px"> <img src="./img/cursar-sar.jpg" width="450px"></p>
<aside class="notes">
<ul>
<li>Comparison of the view in both conditions</li>
<li>The view of the cube is the same
<ul>
<li>In SCREEN condition, note the virtual table is aligned with real table</li>
</ul></li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="scene">Scene</h3>
<p><img src="./img/cursar-scene.jpg" width="700px"></p>
<aside class="notes">
<ul>
<li>Scene was changing between trials</li>
<li>Cube alone in different orientation</li>
<li>Cube <em>and</em> a more complex shape</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="procedures">Procedures</h3>
<video data-autoplay controls class="stretch" src="./img/video.mp4">
</video>
<aside class="notes">
<ol type="1">
<li>Position cursor in starting zone</li>
<li>Zone changes from red to green</li>
<li>Target appears</li>
<li>User go click on target</li>
<li>Comes back to starting zone</li>
</ol>
</aside>
</section><section class="slide level2">

<h3 id="participants">Participants</h3>
<ul>
<li>16 participants</li>
<li>Familiar with mice</li>
<li>Little experience with graphics tablets</li>
<li>No experience with SAR systems</li>
</ul>
</section><section class="slide level2">

<h3 id="design">Design</h3>
<p><img src="./img/cursar-study-design.png" height="650px" style="-webkit-filter: none; filter: none;"></p>
<aside class="notes">
<ul>
<li>Inefficiency: deviation from the most optimal path</li>
</ul>
</aside>
</section><section id="results" class="slide level2">
<h1>Results</h1>
</section><section class="slide level2">

<h3 id="time">Time</h3>
<p>Users were <em>11% faster</em> using a screen vs SAR</p>
<aside class="notes">
<ul>
<li>Screen faster than SAR by 11%</li>
<li>Drop of performance not so important: still usable</li>
<li>Screen probably provide context for interaction</li>
<li>No dead spaces in midair for SCREEN condition</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="inefficiency">Inefficiency</h3>
<p><img class="fragment" src="./img/cursar-heatmap.png" width="950px" style="background:none; border:none; box-shadow:none;"></p>
<aside class="notes">
<ul>
<li>Input modality significant effect.</li>
<li>Tablet is <em>less</em> efficient than mouse</li>
<li>Explained by experience with mice vs graphics tablet</li>
<li>See heatmap figure to show example of this</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="fitts-law">Fitts law</h3>
<p><img src="./img/cursar-fitts-crop.png" height="500px" style="background:none; border:none; box-shadow:none;"></p>
<aside class="notes">
<ul>
<li>We modeled the movement time with a linear regression.</li>
<li>Pointing task in SAR for both mice and tablets still follows Fitts' law and remain predictable</li>
<li>Slower in SAR than SCREEN</li>
<li>More XP to evaluate learning effect</li>
</ul>
<p>Note: <span class="math inline">\(R^2=0.8479\)</span></p>
</aside>
</section><section id="section-19" class="slide level2" data-background="./img/cursar-teaser.png">
<h1></h1>
<h3 id="hybrid-workspaces">Hybrid workspaces</h3>
<aside class="notes">
<ul>
<li>Opens up possibility for truly hybrid applications</li>
<li>Mixes desktop + reality around workspace</li>
</ul>
</aside>
</section><section class="slide level2">

</section></section>
<section><section id="tangible-viewports" class="titleslide slide level1"><h1>Tangible Viewports</h1></section><section id="section-20" class="slide level2" data-background="./img/tports-video-teaser.png" data-transition="fade">
<h1></h1>
<aside class="notes">
<ul>
<li>We continued our investigation varying the different way to leverage the screen context</li>
<li>Here, we keep the screen context for interaction and interact with a physical object when it is located <em>in front of the screen</em></li>
</ul>
</aside>
</section><section id="section-21" class="slide level2" data-background="./img/tports-video-teaser-highlight.png" data-transition="fade">
<h1></h1>
<aside class="notes">
<ul>
<li>Focus on hybrid environment</li>
</ul>
</aside>
</section><section id="section-22" class="slide level2">
<h1></h1>
<video controls src="./img/tports.mp4">
</video>
</section><section class="slide level2">

<h3 id="metaphor">Metaphor</h3>
<img src="./img/tports-cursor-application.png" height="500px">
<aside class="notes">
<p>Working on a physical object becomes the same thing as working on a virtual version in a window</p>
</aside>
</section><section class="slide level2">

<h3 id="pointing-technique-2">Pointing technique</h3>
<img src="./img/tports-cursor.png" height="500px">
<aside class="notes">
<ul>
<li>Same as with CurSAR</li>
<li>Screen is tracked</li>
<li>Behavior of cursor is coherent only for operator</li>
<li>Cursor is visible by <em>everyone</em></li>
</ul>
</aside>
</section><section id="applications" class="slide level2">
<h1>Applications</h1>
</section><section class="slide level2">

<h3 id="painting">Painting</h3>
<p><img src="./img/tports-direct-painting.jpg" height="500px"></p>
</section><section class="slide level2">

<h3 id="programming-augmented-objects">Programming Augmented Objects</h3>
<p><img src="./img/tports-screen-vvvv.jpg" height="500px"></p>
</section><section class="slide level2">

<h3 id="objects-in-sync">Objects in Sync</h3>
<div>
<p><img src="./img/tports-synchro-sync.jpg" height="500px"> <img src="./img/tports-synchro-heatmap.jpg" height="500px"></p>
</div>
</section><section id="section-23" class="slide level2" data-background="./img/tports-video-teaser-bounded.png">
<h1></h1>
</section><section id="section-24" class="slide level2" data-background="./img/tports-video-teaser-unbounded.png">
<h1></h1>
</section></section>
<section><section id="thank-you" class="titleslide slide level1" data-background="./img/logos.png"><h1>Thank You</h1></section></section>
<section><section id="section-25" class="titleslide slide level1"><h1></h1></section><section class="slide level2">

<h3 id="results-1">Results</h3>
<p><img src="./img/table.png" width="950px" style="background:none; border:none; box-shadow:none;"></p>
<div id="refs" class="references">

</div>
</section></section>
    </div>
  </div>

  <script src="./lib/js/head.min.js"></script>
  <script src="./js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Vertical centering of slides
        center: true,
        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,
        height: 720,

        // Optional reveal.js plugins
        dependencies: [
          { src: './lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: './plugin/zoom-js/zoom.js', async: true },
          { src: './plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
