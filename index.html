<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title>Getting Out of Flatland</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="./css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="./css/theme/skydark.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? './css/print/pdf.css' : './css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="./lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">


<section><section id="section" class="titleslide slide level1" data-background="./img/title.jpg"><h1></h1></section><section id="section-1" class="slide level2" data-background="./img/screen-wonderland.png">
<h1></h1>
<aside class="notes">
<ul>
<li>Digital wonderland at fingers' reach</li>
</ul>
</aside>
</section><section id="section-2" class="slide level2" data-background="./img/screen-prisoners.png">
<h1></h1>
<aside class="notes">
<ul>
<li>But cannot touch it</li>
</ul>
</aside>
<!-- Attention -->
</section><section id="section-3" class="slide level2" data-background="./img/sur-fake-5-crop.jpg">
<h1></h1>
<aside class="notes">
<ul>
<li>Devices became portable</li>
<li>But require our whole attention</li>
<li>Either IN the screen our OUT in the world</li>
</ul>
</aside>
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
<div class="copyright" style="right:0px;color:rgb(255,255,255);">
Source: Antoine Geiger's SUR-FAKE
</div>
</section><section class="slide level2">

<h3 id="a-humane-representation-of-thought">A <strong>Humane</strong> Representation of Thought</h3>
<img src="./img/ascent-of-man.jpg" height="300px">
<div class="footnote" style="position: fixed; bottom:-150px; left: 175px;">
<span class="citation" data-cites="Victor2014">Victor, B., 2014. Humane representation of thought: A trail map for the 21st century, in: UIST’14.</span>
</div>
<aside class="notes">
<ul>
<li>Technology constrain our bodies</li>
<li>Only eye and fingers working</li>
<li>Bodies have been neglected</li>
<li>Tip of finger interaction is limiting. Not humane.</li>
<li>Evolution made it so that we think <em>with all our senses</em></li>
</ul>
</aside>
</section><section id="section-4" class="slide level2" data-background="./img/conclusion-real-world.jpg">
<h1></h1>
<h3 id="real-world">Real World</h3>
<aside class="notes">
<p>We <strong>know</strong> how it works</p>
</aside>
</section><section id="section-5" class="slide level2" data-transition="fade">
<h1></h1>
<p><img src="./img/intro-mug.png" height="600px" style="box-shadow: none; background: none;"></p>
</section><section id="section-6" class="slide level2" data-transition="fade">
<h1></h1>
<p><img src="./img/intro-mug-affordance.png" height="600px" style="box-shadow: none; background: none;"></p>
</section><section class="slide level2">

<h3 id="tangible-user-interfaces">Tangible User Interfaces</h3>
<p><img src="./img/radical-atoms.png" height="500px"></p>
<div class="footnote">
<span class="citation" data-cites="Ishii1997">Ishii, H., Ullmer, B., 1997. Tangible bits: Towards seamless interfaces between people, bits and atoms, in: CHI’97.</span><br><span class="citation" data-cites="Ishii2012">Ishii, H. et al., 2012. Radical atoms: Beyond tangible bits, toward transformable materials. interactions.</span>
</div>
</section><section class="slide level2">

<h3 id="augmented-reality">Augmented Reality</h3>
<img src="./img/intro-ar-video-see-through.png">
<aside class="notes">
<ul>
<li>Traditional way is to use video see-through</li>
<li>Can also uses head mounted display</li>
<li>However: requires hardware for user</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="spatial-augmented-reality" style="vertical-align: center;"><em>Spatial</em> Augmented Reality</h3>
Uses projectors or screens <em>in the environments</em> to display information spatially related to this environment
<div class="footnote" style="position: fixed; bottom:-300px; left: 100px;">
<span class="citation" data-cites="Raskar1998a">Raskar, R. et al., 1998. Spatially augmented reality, in: IWAR’98.</span><br><span class="citation" data-cites="Raskar2001a">Raskar, R. et al., 2001. Shader lamps: Animating real objects with image-based illumination, in: Eurographics’01.</span>
</div>
<aside class="notes">
<ul>
<li>SAR instead uses projector or screens <em>in the environment</em></li>
<li>Link with Ubicomp</li>
</ul>
</aside>
<!-- SAR -->
</section><section id="section-7" class="slide level2" data-transition="fade">
<h1></h1>
<p><img src="./img/intro-mug-sar.png"></p>
<aside class="notes">
<ul>
<li>Example mug from before</li>
<li>Normal mug + projector...</li>
</ul>
</aside>
</section><section id="section-8" class="slide level2" data-transition="fade">
<h1></h1>
<p><img src="./img/intro-mug-sar-augmented.png"></p>
<aside class="notes">
<ul>
<li>Creates augmented mug</li>
</ul>
</aside>
</section><section id="augmented-objects" class="slide level2">
<h1>Augmented Objects</h1>
<img src="./img/intro-mug.png" height="500px"> <span style="display:inline-block; width: 50px;"></span> <img src="./img/intro-mug-augmented.png" height="500px">
<aside class="notes">
<ul>
<li>For example, we can augment a normal mug with different functions:
<ul>
<li>Displaying remaining steeping time</li>
<li>Displaying temperature of liquid inside</li>
<li>Handle turns green when everything is OK</li>
</ul></li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="augmented-objects-1">Augmented Objects</h3>
<p><img src="./img/sar-clock.jpg" height="400px"> <img src="./img/teegi-inverse-model.jpg" height="400px"></p>
<aside class="notes">
<ul>
<li>It can also be used to create augmented objects</li>
<li>In these two pictures, <em>white</em> physical objects</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="how-does-it-work">How does it work?</h3>
<!-- TODO: Declutter images -->
</section><section id="section-9" class="slide level2" data-background="./img/sar-pipeline.png">
<h1></h1>
</section><section class="slide level2">

<h3 id="augmented-objects-2">Augmented Objects</h3>
<img src="./img/augmented-object-input-output.png" height="600px">
<aside class="notes">
<p>My objective is to move towards a real-world experience without having to remove technology. Twofold: - By including real world elements with our use of technology - Using technology as a way to reflect on ourselves</p>
</aside>
</section><section class="slide level2">

<h3 id="interaction">Interaction</h3>
<p>How can we <em>interact</em> with digital content hosted on physical objects?</p>
<p><img src="./img/augmented-object-interaction.png" height="400px"></p>
</section><section class="slide level2">

<h3 id="direct-interaction">Direct Interaction</h3>
<img src="./img/dynamic-shader-lamps.jpg" height="400px">
<div class="footnote" style="position: fixed; bottom:-100px; left: 175px;">
<span class="citation" data-cites="Bandyopadhyay2001">Bandyopadhyay, D. et al., 2001. Dynamic shader lamps : painting on movable objects. ISAR’01.</span>
</div>
</section><section class="slide level2">

<h3 id="direct-interaction-1">Direct Interaction</h3>
<img src="./img/physical-virtual-tools.jpg" height="400px"> <span style="display:inline-block; width: 50px;"></span> <img src="./img/miragetable.jpg" height="400px">
<div class="footnote" style="position: fixed; bottom:-100px; left: 100px;">
<span class="citation" data-cites="Marner2009">Marner, M.R. et al., 2009. Physical-virtual tools for spatial augmented reality user interfaces, in: ISMAR’09.</span><br><span class="citation" data-cites="Benko2012">Benko, H. et al., 2012. Miragetable: Freehand interaction on a projected augmented reality tabletop, in: CHI’12.</span>
</div>
</section><section id="section-10" class="slide level2" data-background="./img/cursar-teaser.png">
<h1></h1>
<aside class="notes">
<ul>
<li>Show pointing on real object using direct touch</li>
<li>Tangible interaction is sometimes not enough</li>
<li>So we want to use digital tools</li>
<li>Such tools are often operated on screen</li>
<li>What works great on screen is indirect interaction such as the mouse</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="interaction-1">Interaction</h3>
<img src="./img/cursar-teaser.jpg" height="325px"> <span style="display:inline-block; width: 50px;"></span> <img src="./img/tports-video-teaser.png" height="325px">
<div class="footnote" style="position: fixed; bottom:-100px; left: 100px;">
<span class="citation" data-cites="Gervais2015">Gervais, R. et al., 2015. Pointing in spatial augmented reality from 2D pointing devices, in: INTERACT’15.</span><br>Gervais, R., et al., 2016. Tangible Viewports: Getting out of flatland in desktop environments, in: TEI’16.
</div>
<aside class="notes">
<p>The evaluation of the use of 2D pointing devices – mouse and graphics tablet – in a pointing task in a SAR context compared to a screen condition.</p>
<p>The design, implementation and evaluation of a system enabling the interaction between a typical desktop computer environ- ment – traditional screens, mouse and keyboard – with tangible augmented objects, considering an object design scenario as a main thread.</p>
</aside>
</section><section class="slide level2">

<h3 id="introspection">Introspection</h3>
<p>How can we use augmented objects to reveal hidden information about <em>our own selves</em>?</p>
<p><img src="./img/augmented-object-introspection.png" height="400px"></p>
</section><section class="slide level2">

<h3 id="introspection-1">Introspection</h3>
<img src="./img/mind-mirror.gif" height="400px">
<div class="footnote" style="position: fixed; bottom:-100px; left: 0px;">
<span class="citation" data-cites="Mercier-Ganady2014">Mercier-Ganady, J. et al., 2014. The mind-mirror: See your brain in action in your head using eeg and augmented reality, in: VR’14.</span>
</div>
</section><section class="slide level2">

<h3 id="introspection-2">Introspection</h3>
<img src="./img/bodyviz.jpg" height="400px">
<div class="footnote" style="position: fixed; bottom:-100px; left: 50px;">
<span class="citation" data-cites="Norooz2015">Norooz, L. et al., 2015. BodyVis: A new approach to body learning through wearable sensing and visualization, in: CHI’15.</span>
</div>
</section><section class="slide level2">

<h3 id="introspection-3">Introspection</h3>
<img src="./img/teegi-teaser.jpg" width="600px"> <span style="display:inline-block; width: 50px;"></span> <img src="./img/tobe-coherence.jpg" width="600px">
<div class="footnote" style="position: fixed; bottom:-100px; left: 200px;">
<p>Frey, J., Gervais, R., et al., 2014. Teegi: Tangible EEG interface, in: UIST’14.<br>Gervais, R., Frey, J., et al., 2016. TOBE: Tangible Out-of-Body Experience, in: TEI’16.</p>
</div>
<!-- 
### What is it good for?

---

### Pros
- Anchored in the *real world*
- User is free
- Scales well 
- Collaboration 

---

### Cons
- Projection surface
- Shadows
- Complexity
- *Interaction*
<div class="notes">
Complexity: Calibration with multiple devices (esp. /w multi-proj setup)
</div>
 -->
</section></section>
<section><section id="interaction-2" class="titleslide slide level1" data-background="./img/augmented-object-interaction-bg.png"><h1>Interaction</h1></section><section id="section-11" class="slide level2" data-background="./img/tports-hybrid-workspaces.png">
<h1><!-- Hybrid Workspaces --></h1>
</section><section id="section-12" class="slide level2" data-background="./img/cursar-teaser.png">
<h1></h1>
</section><section id="section-13" class="slide level2" data-transition="fade">
<h1></h1>
<h3 id="standard-way-of-pointing">Standard way of pointing</h3>
<img src="./img/cursar-virtual-pointing.png" height="500px">
<p class="fragment">
Now what happens if...
</p>
</section><section id="section-14" class="slide level2" data-transition="fade">
<h1></h1>
<h3 id="removing-the-screen">Removing the screen</h3>
<img src="./img/cursar-virtual-pointing-no-screen.png" height="500px">
<p class="fragment">
Does pointing still works without a screen?
</p>
</section><section id="study" class="slide level2" data-background="./img/cursar-cube-pointer-drawing.png">
<h1>Study</h1>
</section><section class="slide level2">

<h3 id="questions">Questions</h3>
<p>Differences between <em>SCREEN</em> and <em>SAR</em> conditions for pointing?</p>
<p>Does pointing in SAR follow Fitts' law?</p>
</section><section id="section-15" class="slide level2" data-transition="fade">
<h1></h1>
<h3 id="pointing-technique">Pointing technique</h3>
<p><img src="./img/cursar-virtual-pointing.png" height="500px"></p>
</section><section id="section-16" class="slide level2" data-transition="fade">
<h1></h1>
<h3 id="pointing-technique-1">Pointing technique</h3>
<p><img src="./img/cursar-virtual-pointing-window.png" height="500px"></p>
</section><section class="slide level2">

<h3 id="apparatus">Apparatus</h3>
<p><img src="./img/cursar-setup.png" width="950px" style="background:none; border:none; box-shadow:none;"></p>
<aside class="notes">
<ul>
<li>A: Circle-shaped cursor that follows the geometry of the real world</li>
<li>B: Plane onto which cursor is mapped
<ul>
<li>In SAR, plane is virtual</li>
<li>In SCREEN condition, we use a wooden panel to create a screen there</li>
</ul></li>
<li>C: Guide displayed on the table to help know where the cursor is located</li>
<li>D: Position of the user is known</li>
<li>E: Projector
<ul>
<li>Augment real cube in SAR condition</li>
<li>Projects a virtual cube in SCREEN condition</li>
</ul></li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="screen-vs-sar">SCREEN vs SAR</h3>
<p><img src="./img/cursar-screen.jpg" width="450px"> <img src="./img/cursar-sar.jpg" width="450px"></p>
<aside class="notes">
<ul>
<li>On the left it is a simulated version of what is seen on the right</li>
<li>Comparison of the view in both conditions</li>
<li>The view of the cube is the same
<ul>
<li>In SCREEN condition, note the virtual table is aligned with real table</li>
</ul></li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="scene">Scene</h3>
<p><img src="./img/cursar-scene.jpg" width="700px"></p>
<aside class="notes">
<ul>
<li>Scene was changing between trials</li>
<li>Cube alone in different orientation</li>
<li>Cube <em>and</em> a more complex shape</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="procedures">Procedures</h3>
<video data-autoplay controls class="stretch" src="./img/video.mp4">
</video>
<div class="footnote" style="position: fixed; bottom:-50px; left: 225px;">
<span class="citation" data-cites="MacKenzie1992">MacKenzie, I.S., 1992. Movement time prediction in human-computer interfaces.</span>
</div>
<aside class="notes">
<ol type="1">
<li>Position cursor in starting zone</li>
<li>Zone changes from red to green</li>
<li>Target appears</li>
<li>User go click on target</li>
<li>Comes back to starting zone</li>
</ol>
</aside>
</section><section class="slide level2">

<h3 id="design">Design</h3>
<p><img src="./img/cursar-study-design.png" height="650px" style="-webkit-filter: none; filter: none;"></p>
<aside class="notes">
<ul>
<li>Inefficiency: deviation from the most optimal path</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="participants">Participants</h3>
<ul>
<li>16 participants</li>
<li>Familiar with mice</li>
<li>Little experience with graphics tablets</li>
<li>No experience with SAR systems</li>
</ul>
</section><section id="results" class="slide level2">
<h1>Results</h1>
</section><section class="slide level2">

<h3 id="time">Time</h3>
<p>Users were <em>11% faster</em> using a screen vs SAR</p>
<aside class="notes">
<ul>
<li>Screen faster than SAR by 11%</li>
<li>Drop of performance not so important: still usable</li>
<li>Screen probably provide context for interaction</li>
<li>No dead spaces in midair for SCREEN condition</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="inefficiency">Inefficiency</h3>
<p><img src="./img/cursar-heatmap.png" height="500px" style="-webkit-filter: none; filter: none;"></p>
<aside class="notes">
<ul>
<li>Input modality significant effect.</li>
<li>Tablet is <em>less</em> efficient than mouse</li>
<li>Explained by experience with mice vs graphics tablet</li>
<li>See heatmap figure to show example of this</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="fitts-law">Fitts' law</h3>
<img src="./img/cursar-fitts-eq.png" height="500px" style="-webkit-filter: none; filter: none;">
<div class="footnote" style="position: fixed; bottom:-50px; left: 225px;">
<span class="citation" data-cites="MacKenzie1992">MacKenzie, I.S., 1992. Movement time prediction in human-computer interfaces.</span>
</div>
<aside class="notes">
<ul>
<li>MT: Movement Time</li>
<li>ID: Index of Difficulty</li>
<li>D: Projected target distance in virtual screen</li>
<li>W: Perceived target size</li>
<li>We modeled the movement time with a linear regression.</li>
</ul>
<p>Note: <span class="math inline"><em>R</em><sup>2</sup> = 0.8479</span></p>
</aside>
</section><section id="section-17" class="slide level2" data-background="./img/tports-video-teaser.png" data-transition="fade">
<h1><!-- Tangible Viewports --></h1>
<aside class="notes">
<ul>
<li>We continued our investigation varying the different way to leverage the screen context</li>
<li>Here, we keep the screen context for interaction and interact with a physical object when it is located <em>in front of the screen</em></li>
</ul>
</aside>
</section><section id="section-18" class="slide level2" data-background="./img/tports-video-teaser-highlight.png" data-transition="fade">
<h1></h1>
<aside class="notes">
<ul>
<li>Focus on hybrid environment</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="metaphor">Metaphor</h3>
<img src="./img/tports-cursor-application.png" height="500px">
<aside class="notes">
<p>Working on a physical object becomes the same thing as working on a virtual version in a window</p>
</aside>
</section><section class="slide level2">

<h3 id="pointing-technique-2">Pointing technique</h3>
<img src="./img/tports-cursor.png" height="500px">
<aside class="notes">
<ul>
<li>Same as with CurSAR</li>
<li>Screen is tracked</li>
<li>Behavior of cursor is coherent only for operator</li>
<li>Cursor is visible by <em>everyone</em></li>
</ul>
</aside>
</section><section id="section-19" class="slide level2" data-background-video="./img/tports.mp4">
<h1></h1>
<!-- <video controls src="./img/tports.mp4"></video> -->
</section><section id="applications" class="slide level2">
<h1>Applications</h1>
</section><section class="slide level2">

<h3 id="painting-progamming">Painting / Progamming</h3>
<p><img src="./img/tports-direct-painting.jpg" height="500px"> <span style="display:inline-block; width: 50px;"></span> <img src="./img/tports-screen-vvvv.jpg" height="500px"></p>
</section><section class="slide level2">

<h3 id="objects-in-sync">Objects in Sync</h3>
<p><img src="./img/tports-synchro-sync.jpg" height="500px"> <span style="display:inline-block; width: 50px;"></span> <img src="./img/tports-synchro-heatmap.jpg" height="500px"></p>
</section><section class="slide level2">

<h3 id="text-annotations">Text Annotations</h3>
<p><img src="./img/tports-text.jpg" height="500px"></p>
</section><section class="slide level2">

<h3 id="complementary-representations">Complementary Representations</h3>
<img src="./img/tports-dataviz.jpg" height="500px">
<div class="footnote" style="position: fixed; bottom:-50px; left: 250px;">
<span class="citation" data-cites="Jansen2013">Jansen, Y. et al., 2013. Evaluating the efficiency of physical visualizations, in: CHI.</span>
</div>
</section><section id="section-20" class="slide level2" data-background="./img/tports-video-teaser-bounded.png">
<h1></h1>
</section><section id="section-21" class="slide level2" data-background="./img/tports-video-teaser-unbounded.png">
<h1></h1>
</section><section class="slide level2">

<h3 id="towards-the-desk-as-a-working-space">Towards the Desk as a Working Space</h3>
</section><section class="slide level2">

<h3 id="direct-indirect-combination">Direct-Indirect Combination</h3>
<p><img src="./img/conclusion-direct-indirect-combination-direct.png" height="400px"> <img src="./img/conclusion-direct-indirect-combination-indirect.png" height="400px"></p>
</section><section class="slide level2">

<h3 id="improvised-working-surfaces">Improvised Working Surfaces</h3>
<p><img src="./img/conclusion-improvised-working-surfaces-1.png" height="250px"> <img src="./img/conclusion-improvised-working-surfaces-2.png" height="250px"></p>
<p><img src="./img/conclusion-improvised-working-surfaces-3.png" height="250px"> <img src="./img/conclusion-improvised-working-surfaces-4.png" height="250px"></p>
</section><section class="slide level2">

<p><img src="./img/augmented-object-interaction.png" height="450px"></p>
</section><section class="slide level2">

<p><img src="./img/augmented-object-input-output.png" height="600px"></p>
</section></section>
<section><section id="introspection-4" class="titleslide slide level1" data-background="./img/tobe-coherence-wo-title.png"><h1>Introspection</h1></section><section class="slide level2">

<h3 id="collaboration">Collaboration</h3>
<p><img src="./img/teegi-jeremy.jpg" height="500px"></p>
</section></section>
<section><section id="section-22" class="titleslide slide level1" data-background="./img/teegi-big-head-whats-inside.png"><h1></h1></section><section class="slide level2">

<h3 id="eeg">EEG</h3>
<img src="./img/gtec_headset.jpg" height="500px">
<aside class="notes">
<ul>
<li>EEG: ElectroEncephaloGraphy</li>
<li>Measures electrical activity at the surface of the scalp</li>
<li>Can be used for</li>
<li>Active control (BCIs): thinking about hand movements or imagining mental rotations</li>
<li>Passive measurements</li>
</ul>
</aside>
</section><section id="section-23" class="slide level2" data-background="./img/teegi-eeg-tools.png">
<h1></h1>
<aside class="notes">
<ul>
<li>Current tools are complex and difficult to approach</li>
</ul>
</aside>
</section><section id="section-24" class="slide level2" data-background="./img/teegi-big-head-whats-inside-no-question.png">
<h1></h1>
<h3 id="objectives">Objectives</h3>
<ul>
<li class="fragment">What can EEG measure?</li>
<li class="fragment">How does the brain work?</li>
</ul>
</section><section id="section-25" class="slide level2" data-background="./img/teegi-alison.jpg">
<h1></h1>
<aside class="notes">
<ul>
<li>let users explore their <em>own</em> brain</li>
<li>in <em>real-time</em></li>
</ul>
</aside>
</section><section id="section-26" class="slide level2" data-background-video="./img/teegi.mp4">
<h1><!-- Video teaser --></h1>
</section><section id="section-27" class="slide level2" data-background="./img/teegi-mini-teegis-photo.jpg">
<h1><!-- Tangible filter control --></h1>
<aside class="notes">
<ul>
<li>Users were able to see different brain activity</li>
<li>Filters were controlled using mini-teegis</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="filters">Filters</h3>
<p><img src="./img/teegi-filters.png" height="500px"></p>
</section><section class="slide level2">

<h3 id="synchronized-blinks">Synchronized Blinks</h3>
<video controls data-autoplay loop src="./img/teegi_blinks.mp4" height="500px">
</video>
</section><section class="slide level2">

<h3 id="exposing-the-signal-processing">Exposing the Signal Processing</h3>
<p><img src="./img/teegi-signal-table.jpg" height="500px"></p>
</section><section class="slide level2">

<h3 id="exploratory-study">Exploratory Study</h3>
<p><img src="./img/teegi-questions.jpg" height="600px"></p>
</section><section id="section-28" class="slide level2" data-background="./img/teegi-disco.jpg">
<h1></h1>
<h3 id="teegi-disco" style="color: #eee;">Teegi Disco</h3>
</section></section>
<section><section id="going-further" class="titleslide slide level1" style="color: #eee;" data-background="./img/tobe-tablet-window.jpg"><h1>Going Further</h1></section><section class="slide level2">

<h3 id="inner-mirror">Inner Mirror</h3>
<p><img src="./img/inner-beauty.png" height="500px"></p>
</section><section class="slide level2">

<h3 id="building-your-own-mirror">Building your own mirror</h3>
</section><section class="slide level2">

<h3 id="section-29"></h3>
<p><img src="./img/tobe-pipeline.png" height="600px"></p>
</section><section id="section-30" class="slide level2" data-background-video="./img/tobe.mp4">
<h1><!-- Tobe --></h1>
<!-- <video controls class="stretch" src="./img/tobe.mp4"></video> -->
</section><section id="metrics" class="slide level2" data-background="./img/tobe-gui.jpg">
<h1>Metrics</h1>
</section><section class="slide level2">

<h3 id="sensors-signal-processing">Sensors &amp; Signal Processing</h3>
<p><img src="./img/tobe-sensor-ecg.jpg" width="30%"> <img src="./img/tobe-sensor-breathing.jpg" width="30%"></p>
<p><img src="./img/tobe-sensor-eda.jpg" width="30%"> <img src="./img/tobe-sensor-openbci.jpg" width="30%"></p>
<aside class="notes">
<ul>
<li>ECG</li>
<li>Breathing</li>
<li>EDA</li>
<li>EEG</li>
<li>EOG</li>
</ul>
</aside>
</section><section class="slide level2">

<h3 id="d-printing">3D Printing</h3>
<p><img src="./img/tobe-potato.jpg" height="500px"></p>
</section><section id="section-31" class="slide level2" data-background="./img/tobe-tablet-window.jpg">
<h1></h1>
<h3 id="feedback" style="color: #eee;">Feedback</h3>
</section><section id="section-32" class="slide level2" data-background="./img/tobe-animator.jpg">
<h1></h1>
<h3 id="customization" style="color: #eee;">Customization</h3>
</section><section id="section-33" class="slide level2" data-background="./img/tobe-coherence.jpg">
<h1></h1>
<h3 id="use-case" style="color: #eee;">Use Case</h3>
</section></section>
<section><section id="in-summary" class="titleslide slide level1"><h1>In Summary</h1></section><section id="contributions" class="slide level2">
<h1>Contributions</h1>
<p><img src="./img/augmented-object-input-output.png" height="500px"></p>
</section><section class="slide level2">

<p><img src="./img/summary-interaction.png" height="600px"></p>
</section><section class="slide level2">

<p><img src="./img/summary-introspection.png" height="700px"></p>
</section></section>
<section><section id="section-34" class="titleslide slide level1" data-background="./img/scanning-the-horizon.jpg"><h1><!-- What's next? --></h1></section><section id="section-35" class="slide level2" data-background="./img/conclusion-real-world.jpg">
<h1><!-- The Real World --></h1>
<aside class="notes">
<p>I am very much interested continuing bringing technology closer to the real world</p>
</aside>
</section><section class="slide level2">

<img src="./img/being-and-doing.png">
<aside class="notes">
<p>Because technology has had this tendency to focus on <em>doing</em> while part of the human experience is not only about <em>achieving</em> but also about <em>being</em>.</p>
<p>But I know that the times in my life I felt most alive is when I actually leave technology behind, like</p>
</aside>
</section><section id="section-36" class="slide level2" data-background="./img/tandem.jpg">
<h1></h1>
<aside class="notes">
<p>when I go on a self-supported bike tour with Dominique for a few weeks, juste pedaling all day</p>
</aside>
</section><section id="section-37" class="slide level2" data-background="./img/camping.jpg">
<h1></h1>
<aside class="notes">
<p>and stoping at night to cook and sleep in a tent. When you are out there, you never miss technology.</p>
<p>But when you come back, even if you're still in holidays, technology grabs you back in such a way that you loose this sense of calm you had.</p>
</aside>
</section><section class="slide level2">

<h3 id="designing-for-calmness-and-wellbeing">Designing for Calmness and Wellbeing</h3>
<aside class="notes">
<p>I think we should not have to choose between calm and technology. We should strive to have technology not only to create engagement and completing tasks, but also enabling us to feel calm at times.</p>
</aside>
</section></section>
<section><section id="thank-you" class="titleslide slide level1" data-background="./img/logos.png"><h1>Thank You</h1></section><section id="section-38" class="slide level2" data-background="./img/summary-final.png">
<h1></h1>
</section></section>
<section><section id="section-39" class="titleslide slide level1"><h1></h1></section><section class="slide level2">

<h3 id="results-1">Results</h3>
<p><img src="./img/table.png" width="950px" style="-webkit-filter: none; filter: none;"></p>
</section><section class="slide level2">

<h3 id="tangible-viewports-interaction-space">Tangible Viewports Interaction Space</h3>
<p><img src="./img/tports-table.png" width="950px" style="-webkit-filter: none; filter: none;"></p>
</section><section class="slide level2">

<h3 id="teegi-installation">Teegi Installation</h3>
<p><img src="./img/teegi-setup-drawing.png" height="600px"></p>
</section><section class="slide level2">

<h3 id="tobe-installation">Tobe Installation</h3>
<p><img src="./img/tobe-capscience-setup.png" height="600px"></p>
<div id="refs" class="references">

</div>
</section></section>
    </div>
  </div>

  <script src="./lib/js/head.min.js"></script>
  <script src="./js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: false,
        // Display the page number of the current slide
        slideNumber: 'h-v',
        // Vertical centering of slides
        center: true,
        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,
        height: 720,

        // Optional reveal.js plugins
        dependencies: [
          { src: './lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: './plugin/zoom-js/zoom.js', async: true },
          { src: './plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
